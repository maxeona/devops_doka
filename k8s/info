Установка через kubeadm (вручную)

Условия перед установкой:
1) Преобразования имен (прописать hosts(?))
2) Отключить firewall
3) Отключить selinux(?)
4)Отключить swap 

Установка:
1)Ставим докер
2)Install пакетов для куба
3)Конфигурим мастер ноду
4)Подсоединяем воркера 

Вы установите эти пакеты на все свои машины:
    • kubeadm: команда для начальной загрузки кластера.
    • kubelet: компонент, который работает на всех машинах в вашем кластере и выполняет такие действия, как запуск модулей и контейнеров.
    • kubectl: утилита командной строки для связи с вашим кластером.


Команды запуска

kubeadm init  --pod-network-cidr=172.16.0.0/16 — задаем подсетку адресов для сущностей (подов) куба(выполняется на мастере) → при исполнении этой команды, начинают скачиваться команды

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config  → этот файл можно скинуть себе на локалку, и управлять кубом вне ноды мастера 

получаем токен для подключения к кластеру для воркеров

ШАГ2
Install Network Driver


Главное, что-бы не пересекались подсетки с физ.машинами


kubectl create namespace

Запуск Pod
Обычная последовательность при старте Pod:
1) подготовка api-запроса
     актуальные схемы на kube-apiserver 
1) подготовка и валидация runtime-объекта
2) идентификация и авторизация запроса (токен, сертификат)
цепочка авторизаторов (rbac, abac, node) 
3) обработка запроса admission controllers 
4) сохранение ресурса в etcd
5) основной цикл обработки ресурсов (попадает в определенный контроллер )
6) запуск планировщика
7) магия kubelet
8) магия runtime

Sometimes our pod’s will be don’t run on node, because k8s use taints and tolerations

Taints – позволяют вводить ограничения на размещения модулей на определенных нодах

kubectl taint nodes node1 key1=value1:NoSchedule
добавление ограничения к узлу, что-бы ни один планироващик не помышлял о размещении модуля на данной ноде, без определенного допуска-разрешения 

kubectl taint nodes node1 key1=value1:NoSchedule- (добавление черточки в конце снимает ораничение)
отмена Taint

Кодовая база планировщика 
https://gist.github.com/jvns/5d492d66130a2f47b47820fd6b52eab5


Квоты ресурсов, это функционал при котором, возможно ограничивать системные ресурсы для каждого пространства


***************************************************************************************************************************************************************************
Асбтракции
Namespace- абстракция для разграничения и создания виртуального кластера в кластере(используется для логического разграничения, настройки политики доступа,
а так же для регулирования ресурсов ноды) 

Pod
Service
Ingress
Deployment
ConfigMap

****************************************************************************************************************************************************************************
Using RBAC Authorization
****************************************************************************************************************************************************************************
RBAC-метод регулирования доступа к компьютерным или сетевым ресурсам на основе ролей отдельных пользователей 
в вашей организации 
Юзает rbac.authorization.k8s.io, в которой реализуется группа апи, позволяя динамически настраивать политики через апи куба
Всё общение между компонентами кластера идёт через запросы к API-серверу, и каждый такой запрос как раз авторизуется специальным JWT-токеном. 
Этот токен автоматически генерируется при создании объекта типа ServiceAccount и кладётся в secret. 


!API RBAC объявляет четыре типа объектов Kubernetes: Role , ClusterRole , RoleBinding и ClusterRoleBinding . 

Три ключевых элемента для понимания:
*субъекты - совокупность пользователей и процессов, которые хотят иметь доступ в k8s api
*ресурсы - совокупность объектов к8с апи, которые доступны в кластере. всякие там поды, деплойменты, сервисы, пвс и тд.
*глаголы - операции, которые могут быть выполнены над ресурсами (типа crud операции)


Role and ClusterRole - роль должна быть использовнаа в связке с неймспейсом, а кластер роль распространяется на ресурсы кластера. это не может быть и то, и другое
ClusterRole - можно использовать для разрешения чтения всех пространств имен например (kubectl get pods --all-namespaces)
Role - соединяет ресурсы и глаголы. можно повторно юзать для разных субъектов, но привязаны к одному пространству имен
RoleBinding - связывает субьъектов(всяких пользаков) с ролью, с целью того, что бы субъект был наделен опеределнными праами в соотв. с указанными в роли
список дсотупным апи(глаголов) над определенными ресурсами
Эквивалентом для уровня кластера (т.е. без привязки к пространствам имён) является ClusterRoleBindings.


Более того, допускается использование нескольких схем авторизации одновременно. По умолчанию в кластере используются:

service account tokens — для Service Accounts;
X509 — для Users.

Примеры манифестов:
Role
**********************************************
kind: Role
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: pod-read-create
  namespace: test
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "create"]
  
***********************************************
RoleBinding
***********************************************
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: salme-pods
  namespace: test
subjects:
- kind: User
  name: jsalmeron
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: pod-read-create
  apiGroup: rbac.authorization.k8s.io
**************************************************  

Немного о субъектах:
Users — глобальные пользователи, предназначены для людей или процессов, живущих вне кластера;
ServiceAccounts — ограниченные пространством имён и предназначенные для процессов внутри кластера, запущенных на подах.

Создание нового файла конфигурации:
kubectl config --kubeconfig=./config set-cluster k8s --server=https://{ip}:6443 \
--certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true

Добавление нового пользователя:
kubectl config --kubeconfig=./config set-credentials {name_new_user} --client-key={name_new_user}.key --client-certificate={name_new_user}.crt --embed-certs=true

Добавление контекста: 
kubectl config --kubeconfig=./config set-context {name_context} --cluster=k8s --user={name_new_user} --namespace {name_ns}
Контекст связывает пользователя и кластер 




















